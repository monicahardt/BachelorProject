{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Notebook for Monha's and Bemi's Bachelor Project\n",
    "\n",
    "## Content\n",
    "\n",
    "In this notebook we will:\n",
    "\n",
    "1. Aggrigate our data into usable travel sequences with only the relevant data \n",
    "2. Analyse the appropriate data\n",
    "3. Create an embedding space using Word2Vec\n",
    "\n",
    "We will use the following format for the structure of the file:\n",
    "1. MD file to describe the intention of the following code followed by an explanation of the results from the code if any\n",
    "2. Code block to write code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup\n",
    "\n",
    "Please pip install the correct libraries for the following code to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas # Pandas for data handling\n",
    "%pip install numpy  # Maths stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import\n",
    "\n",
    "The data used in this notebook is extracted from the Journeys table from the DB. \n",
    "\n",
    "The data in question contains ~43 mil rows. This data is all journeys traveled in the timespan of ~4 years. For the purpose of this project we wish to filter the data, such that we only work with journeys within Copenhagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/All_Journeys.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering data\n",
    "\n",
    "In order to filter our data, XXX checks need to be made to be certain a journey is within cph as well as containing information relevant for our purpose. \n",
    "\n",
    "For a journey to be within cph they need to only make use of zone 1 through 4\n",
    "1. Check if *internalStartZones* only contain zones within cph\n",
    "2. Check if *internalValidZones* only contain zones within cph\n",
    "\n",
    "For a journey to be relevant for the project, we need the fields *StartStop*, *EndStop*, *SearchStart* and *SearchEnd* to be either fully filled out or partly - that is, if Start- and EndStop are null, then SearchStart and -End need to be filled. Likewise, the fields must not match in their values; a journeys start and end should not be the same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copenhagen filtering\n",
    "condition_1_cph = (\n",
    "    (data['internalValidZones'].str.match(r'^(1001|1002|1003|1004)(,(1001|1002|1003|1004))*$')\n",
    "    | # or\n",
    "    pd.isna(data['internalValidZones']))\n",
    "    )\n",
    "\n",
    "condition_2_cph = (\n",
    "    (data['internalStartZones'].str.match(r'^(1001|1002|1003|1004)$'))\n",
    "    | # or\n",
    "    pd.isna(data['internalStartZones'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph_data = data[(condition_1_cph)]\n",
    "cph_data = cph_data[(condition_2_cph)]\n",
    "\n",
    "cph_data = cph_data[ ~ (cph_data['SearchStart'].str.contains(\"okation\", na=False)\n",
    "                                             | #Or\n",
    "                                             cph_data['SearchStart'].str.contains(\"zoner\", na=False))]\n",
    "cph_data = cph_data[( ~ (cph_data['SearchEnd'].str.contains(\"zoner\", na=False) \n",
    "                                            | #Or\n",
    "                                            cph_data['SearchEnd'].str.contains(\"okation\", na=False)))]\n",
    "\n",
    "# next two filters are English filters of the first\n",
    "cph_data = cph_data[( ~ (cph_data['SearchEnd'].str.contains(\"zones\", na=False) \n",
    "                                            | #Or\n",
    "                                            cph_data['SearchEnd'].str.contains(\"ocation\", na=False)))]\n",
    "\n",
    "cph_data = cph_data[( ~ (cph_data['SearchStart'].str.contains(\"zones\", na=False) \n",
    "                                            | #Or\n",
    "                                            cph_data['SearchStart'].str.contains(\"ocation\", na=False)))]\n",
    "\n",
    "# Next filter is to remove entries where one of the matching search-x or x-stop are Null\n",
    "cph_data = cph_data[(\n",
    "                                        ( ~ (pd.isna(cph_data['SearchStart'])) & ~ (pd.isna(cph_data['SearchEnd'])))\n",
    "                                        | # Or\n",
    "                                        ( ~ (pd.isna(cph_data['StartStop'])) & ~ (pd.isna(cph_data['EndStop'])))\n",
    "                                        )]\n",
    "\n",
    "# Next filter removes all entries where SearchStart and SearchEnd contain the same value\n",
    "cph_data = cph_data[(\n",
    "                        ~(cph_data['SearchStart'] == cph_data['SearchEnd'])\n",
    "                        )]\n",
    "\n",
    "cph_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing to see whether our filtering worked\n",
    "\n",
    "Since we are handling a very large amount of data, it can be difficult to scim through the data in order to see if it is as intended. These tests are used in order to detect whether or not rows that are not supposed to be in our data is in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1 for whether our data contain seachEnd with contains 'lokation' or 'location'\n",
    "lokation_count = cph_data[cph_data['SearchEnd'].str.contains(\"okation\", na=False)].count()\n",
    "print(f\"Amount of 'Lokation' entires in 'SearchEnd' : {lokation_count['SearchEnd']}\")\n",
    "\n",
    "location_count = cph_data[cph_data['SearchEnd'].str.contains(\"ocation\", na=False)].count()\n",
    "print(f\"Amount of 'Location' entires in 'SearchEnd' : {lokation_count['SearchEnd']}\")\n",
    "\n",
    "# Test 2 for whether our data contain seachStart with contains 'lokation' or 'location'\n",
    "lokation_count_s = cph_data[cph_data['SearchStart'].str.contains(\"okation\", na=False)].count()\n",
    "print(f\"Amount of 'Lokation' entires in 'SearchStart' : {lokation_count_s['SearchStart']}\")\n",
    "\n",
    "location_count_s = cph_data[cph_data['SearchStart'].str.contains(\"ocation\", na=False)].count()\n",
    "print(f\"Amount of 'Location' entires in 'SearchStart' : {location_count_s['SearchStart']}\")\n",
    "\n",
    "# Test 3 for whether our data contain SearchStart with 'zones' or 'zoner'\n",
    "zones_count = cph_data[cph_data['SearchEnd'].str.contains(\"zones\", na=False)].count()\n",
    "print(f\"Amount of 'zones' entires in 'SearchEnd' : {zones_count['SearchEnd']}\")\n",
    "\n",
    "zones_count_r = cph_data[cph_data['SearchEnd'].str.contains(\"zoner\", na=False)].count()\n",
    "print(f\"Amount of 'zoner' entires in 'SearchEnd' : {zones_count_r['SearchEnd']}\")\n",
    "\n",
    "# Test 4 for whether our data contain None in 3 or more fields (startStop, EndStop, SearchStart and SearchEnd)\n",
    "num_nulls = cph_data[['StartStop', 'EndStop', 'SearchStart', 'SearchEnd']].isna().sum(axis=1)\n",
    "b = (num_nulls >= 3).any()\n",
    "print(f\"Does the data contain a row which 3 of StartStop, EndStop, SearchStart or SearchEnd is null: {b}\")\n",
    "\n",
    "# Test 5 for whether our data contain duplicates in matching fields, i.e. StartStop == EndStop\n",
    "duplicates_in_stop = cph_data[(cph_data['StartStop'] == cph_data['EndStop'])].count()\n",
    "print(f\"Amount of matching values in StartStop and EndStop : {duplicates_in_stop['StartStop']}\")\n",
    "\n",
    "\n",
    "# Test 6 for whether our data contain duplicates in matching fields, i.e. SearchStart == SearchEnd\n",
    "duplicates_in_stop = cph_data[(cph_data['SearchStart'] == cph_data['SearchEnd'])].count()\n",
    "print(f\"Amount of matching values in SearchStart and SearchEnd : {duplicates_in_stop['SearchStart']}\")\n",
    "\n",
    "# Test 7 for whether our data contain three of the fields filled.\n",
    "num_filled = ~(cph_data[['StartStop', 'EndStop', 'SearchStart', 'SearchEnd']].isna()).sum(axis=1)\n",
    "b = (num_filled == 3).any()\n",
    "print(f\"Does the data contain a row which 3 of StartStop, EndStop, SearchStart or SearchEnd are filled: {b}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequences\n",
    "\n",
    "We now wish to make sequences from the journeys. The sequnces should either be a value pair of SearchStart and Searchend or a pair of StartStop and EndStop. To do this we simply collect the pairs from the dataframe where StartStop and EndStop Id's are \"translated\" to station names. \n",
    "\n",
    "When making the sequences, certain questions arrise about the data. For instance, of the 3,4 mil datapoints, only 64 of the datapoints contain a value *only* in StartStop and EndStop. (```python test_df[~(pd.isna(test_df['StartStop'])) & (pd.isna(test_df['SearchStart']))]```)\n",
    "\n",
    "Another important decision is deciding on how to extract stations from SearchStart and SearchEnd, since a lot of the entries does not consist of a directly matching station. i.e. 'Hovedebanegården' being the SearchStart for the station 'København H'. Thus we need to match these inconsistent strings with a consistent naming convention. \n",
    "\n",
    "The first step in the creation of sequences is to prase our strings to fit the same format. A bunch of stations have '(01)' or another number in the parenthesis, probably incidating either which zones the user is searching from or where they are going. We are not interested in this number. The following regex will handle this parsing:\n",
    "\n",
    "```regex \n",
    "    r'[(]\\d\\d[)]'\n",
    "```\n",
    "\n",
    "Likewise we are not interested in detailed searches like a full address; Klokkerhøjen 6 st, 2400 København NV, Denmark. Thus we wish to remove all symbols after ','. We do this with the following regex:\n",
    "\n",
    "```regex\n",
    "    r'(,.*$)'\n",
    "```\n",
    "\n",
    "(THIS ONE ALSO REPLACES THE FIRST REGEX)\n",
    "Lastly we wish to remove all '(togbus)' parts of a string. Here we do note, that the strings might contain '(metro)' which we are interested in keeping. Thus we need to remove all symbols inside a parenthesis but not if the symbols are the string 'metro'. This will be done partly through code and partly with the regex:\n",
    "\n",
    "```regex\n",
    "    r'\\s*\\([^)]*\\)'\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph_data = pd.read_csv('../Data/cph_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pattern_for_comma = r'(,.*$)'\n",
    "pattern_for_parenthesis = r'\\s*\\([^)]*\\)'\n",
    "pattern_for_parenthesis_number = r'[(]\\d\\d[)]'\n",
    "\n",
    "sequences = []\n",
    "\n",
    "station_counter = {}\n",
    "\n",
    "\n",
    "def get_sequence(row) -> None:\n",
    "    initial_start   = row['SearchStart']\n",
    "    initial_end     = row['SearchEnd']\n",
    "    if pd.notna(initial_start):\n",
    "        start   = re.sub(pattern_for_comma, \"\", initial_start)\n",
    "        end     = re.sub(pattern_for_comma, \"\", initial_end)\n",
    "\n",
    "\n",
    "\n",
    "        if \"Metro\" not in start:\n",
    "            start   = re.sub(pattern_for_parenthesis, \"\", start)\n",
    "        else: \n",
    "            start   = re.sub(pattern_for_parenthesis_number, \"\", start)\n",
    "                \n",
    "        if \"Metro\" not in end:\n",
    "            end   = re.sub(pattern_for_parenthesis, \"\", end)\n",
    "        else:\n",
    "            end   = re.sub(pattern_for_parenthesis_number, \"\", end)\n",
    "        \n",
    "        if start.strip() != \"\":\n",
    "            sequences.append([start.strip(), end.strip()])\n",
    "            \n",
    "            start = start.strip()\n",
    "            end = end.strip()\n",
    "            \n",
    "            if start not in station_counter:\n",
    "                station_counter[start] = 1\n",
    "            else:\n",
    "                station_counter[start] = station_counter[start] + 1\n",
    "            \n",
    "            if end not in station_counter:\n",
    "                station_counter[end] = 1\n",
    "            else:\n",
    "                station_counter[end] = station_counter[end] + 1\n",
    "        \n",
    "cph_data.apply(get_sequence, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = dict(sorted(station_counter.items(), key = lambda x: x[1], reverse = True)[:10])\n",
    "res\n",
    "\n",
    "# Top used stations are:\n",
    "# 'København H': 402727,\n",
    "# 'Nørreport St.': 342289,\n",
    "# 'Kongens Nytorv St. (Metro)': 326808,\n",
    "# 'CPH Lufthavn': 235769,\n",
    "# 'Refshaleøen': 189228,\n",
    "# 'Hovedbanegården': 156454,\n",
    "# 'Ørestad St.': 139841,\n",
    "# 'København H (Metro)': 115016,\n",
    "# 'Christianshavn St. (Metro)': 106272,\n",
    "# 'Amagerbro St. (Metro)': 101808\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for station in station_counter.keys():\n",
    "    if station.__contains__(\"Kongens Nytorv\"):\n",
    "        print(f\"{station} : {station_counter[station]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with the problem of the same places in Copenhagen being searched with different naming conventions (and languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install geopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from geopy.distance import geodesic\n",
    "geolocator = Nominatim(user_agent=\"my_geocoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- geopy is a Python client for several popular geocoding web services.\n",
    "\n",
    "- geopy makes it easy for Python developers to locate the coordinates of addresses, cities, countries, and landmarks across the globe using third-party geocoders and other data sources.\n",
    "\n",
    "- geopy includes geocoder classes for the OpenStreetMap Nominatim, Google Geocoding API (V3), and many other geocoding services. The full list is available on the Geocoders doc section. Geocoder classes are located in geopy.geocoders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A small test testing some random stations in Copenhagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Top used stations are:\n",
    "# 'København H': 402727,\n",
    "# 'Nørreport St.': 342289,\n",
    "# 'Kongens Nytorv St. (Metro)': 326808,\n",
    "# 'CPH Lufthavn': 235769,\n",
    "# 'Refshaleøen': 189228,\n",
    "# 'Hovedbanegården': 156454,\n",
    "# 'Ørestad St.': 139841,\n",
    "# 'København H (Metro)': 115016,\n",
    "# 'Christianshavn St. (Metro)': 106272,\n",
    "# 'Amagerbro St. (Metro)': 101808\n",
    "\n",
    "\n",
    "place1 = 'København H'  # 55.6727587 12.564678938785772\n",
    "place2 = 'Nørreport St.' #55.6840689 12.5725383\n",
    "# place3 = 'Kongens Nytorv St. (Metro)'\n",
    "place4 = 'CPH Lufthavn' #55.6091282 12.650982248393536\n",
    "place5 = 'Refshaleøen' #55.693321499999996 12.61966813806588\n",
    "place6 = 'Hovedbanegården' #55.6727587 12.564678938785772\n",
    "place7 = 'Ørestad St.' # 55.6727587 12.564678938785772\n",
    "# place8 = 'København H (Metro)'\n",
    "# place9 = 'Christianshavn St. (Metro)'\n",
    "# place10 = 'Amagerbro St. (Metro)'\n",
    "\n",
    "location_place1 = geolocator.geocode(place1)\n",
    "location_place2 = geolocator.geocode(place2)\n",
    "# location_place3 = geolocator.geocode(place3)\n",
    "location_place4 = geolocator.geocode(place4)\n",
    "location_place5 = geolocator.geocode(place5)\n",
    "location_place6 = geolocator.geocode(place6)\n",
    "# location_place8 = geolocator.geocode(place8)\n",
    "# location_place9 = geolocator.geocode(place9)\n",
    "# location_place10 = geolocator.geocode(place10)\n",
    "\n",
    "print(\"Location 1:\", location_place1.latitude, location_place1.longitude)\n",
    "print(\"Location 2:\", location_place2.latitude, location_place2.longitude)\n",
    "# print(\"Location 3:\", location_place3.latitude, location_place3.longitude)\n",
    "print(\"Location 4:\", location_place4.latitude, location_place4.longitude)\n",
    "print(\"Location 5:\", location_place5.latitude, location_place5.longitude)\n",
    "print(\"Location 6:\", location_place6.latitude, location_place6.longitude)\n",
    "print(\"Location 7:\", location_place6.latitude, location_place6.longitude)\n",
    "# print(\"Location 8:\", location_place8.latitude, location_place8.longitude)\n",
    "# print(\"Location 9:\", location_place9.latitude, location_place9.longitude)\n",
    "# print(\"Location 10:\", location_place10.latitude, location_place10.longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A first tester to find all stations in the sequences that match around the coordinates of 'Hovedbanegården'\n",
    "The targets we want that are known to us is specifically 'København H' / 'Hovedbanegården' and 'Cph lufthavn'/ 'Kbh lufthavnen' /'Lufthavnen st'/ 'Kastrup st'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to create a list of unique stationnames to use with the geolocator to save time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_stations_set = set()\n",
    "for seq in sequences:\n",
    "    for place in seq:\n",
    "        distinct_stations_set.add(place)\n",
    "\n",
    "# Convert the set back to a list\n",
    "unique_stations_list = list(distinct_stations_set)\n",
    "print(unique_stations_list)\n",
    "len(unique_stations_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "from geopy.exc import GeocoderUnavailable\n",
    "from geopy.exc import GeocoderQueryError\n",
    "import time\n",
    "# List to store places close to the target coordinates\n",
    "\n",
    "#should return a list of all locations that should be mapped to the target coordinations station\n",
    "def get_locations_close_to_target(targetCoords, unique_stations):\n",
    "    iteration_counter = 0\n",
    "    places_close_to_target = []\n",
    "    # Iterate through the sequences and their elements\n",
    "    for place in unique_stations:\n",
    "        \n",
    "        if \"Metro\" in place:\n",
    "            continue\n",
    "        \n",
    "        iteration_counter += 1\n",
    "        # Check if the place already exists in places_close_to_target\n",
    "        if any(place == p for p in places_close_to_target):\n",
    "            continue  # Skip this place if it already exists in places_close_to_target\n",
    "\n",
    "        retries = 3\n",
    "        while retries > 0:\n",
    "            try:\n",
    "                location = geolocator.geocode(place, timeout=None)\n",
    "                if location is not None:\n",
    "                    place_coordinates = (location.latitude, location.longitude)\n",
    "                    distance_to_target = geodesic(targetCoords, place_coordinates).kilometers\n",
    "                    if distance_to_target < 0.1:  # Adjust this threshold as needed\n",
    "                        places_close_to_target.append(place)  # Append place name only\n",
    "                        unique_stations.remove(place)\n",
    "                        print(f\"location number in list: {iteration_counter}\")\n",
    "                break  # Exit the retry loop if successful\n",
    "            except GeocoderTimedOut as e:\n",
    "                retries -= 1\n",
    "                if retries == 0:\n",
    "                    print(f\" Max retries exceeded for {place}. Skipping...\")\n",
    "                time.sleep(1)  # Add a delay between retries to avoid overwhelming the server\n",
    "            except GeocoderUnavailable as e:\n",
    "                print(f\"Geocoder unavailable: {e}\")\n",
    "                time.sleep(5)  # Wait for 5 seconds before retrying\n",
    "            except GeocoderQueryError as e:\n",
    "                print(f\"Geocoder query error: {e}\")\n",
    "                break  # Exit the retr  y loop if there's a query error\n",
    "\n",
    "    return places_close_to_target, unique_stations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "København_H  =    (55.6727587, 12.564678938785772)\n",
    "Nørreport_St =    (55.6840689, 12.5725383)\n",
    "CPH_Lufthavn =    (55.6091282, 12.650982248393536)\n",
    "Refshaleøen  =    (55.693321499999996, 12.61966813806588)\n",
    "# Hovedbanegården = (55.6727587, 12.564678938785772)\n",
    "\n",
    "all_stations_to_change_kbh_h, updated_list           = get_locations_close_to_target(København_H, unique_stations_list)\n",
    "all_stations_to_change_nørreport, updated_list       = get_locations_close_to_target(Nørreport_St, updated_list)\n",
    "all_stations_to_change_cph_lufthavn, updated_list    = get_locations_close_to_target(CPH_Lufthavn, unique_stations_list)\n",
    "all_stations_to_change_refshaleøen , updated_list    = get_locations_close_to_target(Refshaleøen, updated_list)\n",
    "\n",
    "# lufthavnen_coords = (55.595098, 12.6179894)\n",
    "# hovedbanen_coords = (55.595098, 12.6179894)\n",
    "# lufthavnen = get_locations_close_to_target(lufthavnen_coords,unique_stations_list)\n",
    "# hovedbanen = get_locations_close_to_target(hovedbanen_coords,unique_stations_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sequence check if the name is in the list of locations that should be interpreted as 'København H' and replace these with København H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the sequences\n",
    "for i, sequence in enumerate(sequences):\n",
    "    station1, station2 = sequence\n",
    "    # Check if the first station matches any place close to København H\n",
    "    for place, distance in places_close_to_target:\n",
    "        if station1 == place:\n",
    "            sequences[i][0] = 'København H'\n",
    "    # Check if the second station matches any place close to København H\n",
    "    for place, distance in places_close_to_target:\n",
    "        if station2 == place:\n",
    "            sequences[i][1] = 'København H'\n",
    "\n",
    "# Print the updated sequences\n",
    "print(\"Updated sequences:\")\n",
    "for sequence in sequences:\n",
    "    print(sequence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Async try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "from geopy.exc import GeocoderUnavailable\n",
    "from geopy.exc import GeocoderQueryError\n",
    "import time\n",
    "# List to store places close to the target coordinates\n",
    "\n",
    "#should return a list of all locations that should be mapped to the target coordinations station\n",
    "async def get_locations_close_to_target(target_coords, unique_stations):\n",
    "    iteration_counter = 0\n",
    "    places_close_to_target = []\n",
    "    # Iterate through the sequences and their elements\n",
    "    for place in unique_stations:\n",
    "        iteration_counter += 1\n",
    "        if \"Metro\" in place:\n",
    "            continue\n",
    "        \n",
    "        # Check if the place already exists in places_close_to_target\n",
    "        if any(place == p for p in places_close_to_target):\n",
    "            continue  # Skip this place if it already exists in places_close_to_target\n",
    "        \n",
    "        target = await async_geo(place, target_coords)#append to the list the result of running the async function\n",
    "        print(f\"Have returning from async call in ite: {iteration_counter}\")\n",
    "        if target is not None:\n",
    "            print(f\"{iteration_counter}, {target}\")\n",
    "            places_close_to_target.append(target)\n",
    "\n",
    "    return places_close_to_target\n",
    "\n",
    "async def async_geo(session, place, target_coords):\n",
    "        retries = 3\n",
    "        while retries > 0:\n",
    "            try:\n",
    "                location = geolocator.geocode(place, timeout=None)\n",
    "                if location is not None:\n",
    "                    place_coordinates = (location.latitude, location.longitude)\n",
    "                    distance_to_target = geodesic(target_coords, place_coordinates).kilometers\n",
    "                    if distance_to_target < 0.1:  # Adjust this threshold as needed\n",
    "                        return place\n",
    "                    else:\n",
    "                        return\n",
    "                break  # Exit the retry loop if successful\n",
    "            except GeocoderTimedOut as e:\n",
    "                retries -= 1\n",
    "                if retries == 0:\n",
    "                    print(f\" Max retries exceeded for {place}. Skipping...\")\n",
    "                time.sleep(1)  # Add a delay between retries to avoid overwhelming the server\n",
    "            except GeocoderUnavailable as e:\n",
    "                print(f\"Geocoder unavailable: {e}\")\n",
    "                time.sleep(5)  # Wait for 5 seconds before retrying\n",
    "            except GeocoderQueryError as e:\n",
    "                print(f\"Geocoder query error: {e}\")\n",
    "                break  # Exit the retr  y loop if there's a query error\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "København_H_async  =    (55.6727587, 12.564678938785772)\n",
    "all_stations_to_change_kbh_h_async          = await get_locations_close_to_target(København_H_async, unique_stations_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stations_to_change_kbh_h_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('sequences.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
