{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding space\n",
    "\n",
    "This document will explore the training and analysis of our embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scipy==1.10.0\n",
    "%pip install gensim\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install matplotlib\n",
    "%pip install pacmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/sequences.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    sequences = list(reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=sequences,   # This is the data that we wish to create notes on. This will take all unique words (stations) and put them in the NN\n",
    "                 vector_size=300,       # Amount of dimension\n",
    "                 min_count=10,          # If the number of occurences of this station is less than 10, then we are not interested in having it in our embedding. -- THIS NEED TO BE LOOKED AT\n",
    "                 workers=4              # Amount of cores used for training and so forth.\n",
    "                 )         \n",
    "\n",
    "model.build_vocab(sequences)\n",
    "model.train(sequences, total_examples=model.corpus_count, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanløse test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Initialize a Counter to store station counts\n",
    "station_counter = Counter()\n",
    "list_of_stations_with_vanløse = []\n",
    "\n",
    "# Iterate over each journey list\n",
    "for journey in sequences:\n",
    "    # Check if 'Vanløse St.' is present in the journey\n",
    "    if 'Vanløse St.' in journey:\n",
    "        # Iterate over each station in the journey\n",
    "        for station in journey:\n",
    "            # Exclude 'Vanløse St.' from counting\n",
    "            if station != 'Vanløse St.':\n",
    "                # Increment the count for the station\n",
    "                station_counter[station] += 1\n",
    "\n",
    "# Sort the station counts by count (descending order)\n",
    "sorted_stations = sorted(station_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "for sta in sorted_stations:\n",
    "    if sta[1] > 7:\n",
    "        list_of_stations_with_vanløse.append(sta[0])\n",
    "\n",
    "# Print the station counts\n",
    "for station, count in sorted_stations:\n",
    "    print(f\"{station}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_stations_with_vanløse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def tsne_plot(model):\n",
    "    \"Create TSNE model and plot it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in model.wv.index_to_key:\n",
    "        tokens.append(model.wv[word])\n",
    "        if(word) in list_of_stations_with_vanløse:\n",
    "            labels.append(word)\n",
    "        else:\n",
    "            labels.append(None)\n",
    "       \n",
    "    tsne_model = TSNE(perplexity=5, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(np.array(tokens))\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(18, 18)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        \n",
    "        plt.annotate(labels[i],\n",
    "                    xy=(x[i], y[i]),\n",
    "                    xytext=(5, 2),\n",
    "                    textcoords='offset points',\n",
    "                    ha='right',\n",
    "                    va='bottom')\n",
    "    plt.show()\n",
    "   \n",
    "tsne_plot(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# København H (Metro) Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Initialize a Counter to store station counts\n",
    "station_counter_kbh_metro = Counter()\n",
    "list_of_stations_with_kbh_metro = []\n",
    "\n",
    "# Iterate over each journey list\n",
    "for journey in sequences:\n",
    "    if 'København H (Metro)' in journey:\n",
    "        # Iterate over each station in the journey\n",
    "        for station in journey:\n",
    "            if station != 'København H (Metro)':\n",
    "                station_counter_kbh_metro[station] += 1\n",
    "\n",
    "# Sort the station counts by count (descending order)\n",
    "sorted_stations_kbh = sorted(station_counter_kbh_metro.items(), key=lambda x: x[1], reverse=True)\n",
    "for sta in sorted_stations_kbh:\n",
    "    if sta[1] > 7:\n",
    "        list_of_stations_with_kbh_metro.append(sta[0])\n",
    "\n",
    "# Print the station counts\n",
    "for station, count in sorted_stations_kbh:\n",
    "    print(f\"{station}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_stations_with_kbh_metro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot(model):\n",
    "    \"Create TSNE model and plot it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in model.wv.index_to_key:\n",
    "        tokens.append(model.wv[word])\n",
    "        if(word) in list_of_stations_with_kbh_metro:\n",
    "            labels.append(word)\n",
    "        else:\n",
    "            labels.append(None)\n",
    "       \n",
    "    tsne_model = TSNE(perplexity=5, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(np.array(tokens))\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(18, 18)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        \n",
    "        plt.annotate(labels[i],\n",
    "                    xy=(x[i], y[i]),\n",
    "                    xytext=(5, 2),\n",
    "                    textcoords='offset points',\n",
    "                    ha='right',\n",
    "                    va='bottom')\n",
    "    plt.show()\n",
    "   \n",
    "tsne_plot(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: ```https://towardsdatascience.com/visualizing-your-embeddings-4c79332581a9```\n",
    "#### Embedding space\n",
    "\n",
    "***Mathematical intuition***: Given two points Xi, Xj, the farther they are, the higher their distance dj|i, the higher their dissimilarity, and the lower the probability that they will consider each other neighbors.\n",
    "\n",
    "***Key concept***: the further away two embeddings are in the space, the more dissimilar they are.\n",
    "\n",
    "#### Perplexity\n",
    "***Mathematical intuition***: The higher the perplexity, the more likely it is to consider points that are far away as neighbors.\n",
    "\n",
    "***Advice***: The authors of SNE and t-SNE (yes, t-SNE has perplexity as well) use perplexity values between five and 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = Word2Vec(sentences=sequences,   # This is the data that we wish to create notes on. This will take all unique words (stations) and put them in the NN\n",
    "                 vector_size=300,       # Amount of dimension\n",
    "                 min_count=10,          # If the number of occurences of this station is less than 10, then we are not interested in having it in our embedding. -- THIS NEED TO BE LOOKED AT\n",
    "                 workers=4              # Amount of cores used for training and so forth.\n",
    "                 )         \n",
    "\n",
    "model_new.build_vocab(sequences)\n",
    "model_new.train(sequences, total_examples=model.corpus_count, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot(model):\n",
    "    \"Create TSNE model and plot it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in model_new.wv.index_to_key:\n",
    "        tokens.append(model_new.wv[word])\n",
    "        if(word) in list_of_stations_with_kbh_metro:\n",
    "            labels.append(word)\n",
    "        else:\n",
    "            labels.append(None)\n",
    "       \n",
    "    tsne_model = TSNE(perplexity=50, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(np.array(tokens))\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(18, 18)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        \n",
    "        plt.annotate(labels[i],\n",
    "                    xy=(x[i], y[i]),\n",
    "                    xytext=(5, 2),\n",
    "                    textcoords='offset points',\n",
    "                    ha='right',\n",
    "                    va='bottom')\n",
    "    plt.show()\n",
    "   \n",
    "tsne_plot(model_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing using PaCMAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pacmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing with model of all journeys cph trained 5000 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_all = Word2Vec.load(\"../Data/word2vec_epoch_5000.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## paCMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pacmap\n",
    "\n",
    "# Assuming model_new is your Word2Vec model\n",
    "station_names = model_all.wv.index_to_key\n",
    "\n",
    "# Generate labels based on whether \"metro\" is in the station name\n",
    "labels = []\n",
    "for station_name in station_names:\n",
    "    if \"metro\" in station_name.lower():\n",
    "        labels.append(\"Metro\")\n",
    "    else:\n",
    "        labels.append(\"Non-Metro\")\n",
    "\n",
    "# Convert labels to numerical format\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(labels)\n",
    "numeric_labels = label_encoder.transform(labels)\n",
    "\n",
    "# Convert Word2Vec vectors to numpy array\n",
    "X = model_all.wv.vectors\n",
    "\n",
    "# Initializing the PaCMAP instance\n",
    "embedding = pacmap.PaCMAP(n_components=2, n_neighbors=None, MN_ratio=0.5, FP_ratio=2.0) \n",
    "\n",
    "# Fit the data\n",
    "X_transformed = embedding.fit_transform(X, init=\"pca\")\n",
    "\n",
    "# Visualize the embedding with different colors for \"Metro\" and \"Non-Metro\" stations\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "scatter = ax.scatter(X_transformed[:, 0], X_transformed[:, 1], c=numeric_labels, cmap='coolwarm', s=0.6)\n",
    "plt.colorbar(scatter, ax=ax)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot(model):\n",
    "    \"Create TSNE model and plot it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in model.wv.index_to_key:\n",
    "        tokens.append(model.wv[word])\n",
    "        #labels.append(word)\n",
    "       \n",
    "    tsne_model = TSNE(perplexity=50, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(np.array(tokens))\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(18, 18)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        \n",
    "        # plt.annotate(labels[i],\n",
    "        #             xy=(x[i], y[i]),\n",
    "        #             xytext=(5, 2),\n",
    "        #             textcoords='offset points',\n",
    "        #             ha='right',\n",
    "        #             va='bottom')\n",
    "    plt.show()\n",
    "   \n",
    "tsne_plot(model_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
