{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/All_Journeys.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copenhagen filtering\n",
    "condition_1_cph = (\n",
    "    (data['internalValidZones'].str.match(r'^(1001|1002|1003|1004)(,(1001|1002|1003|1004))*$')\n",
    "    | # or\n",
    "    pd.isna(data['internalValidZones']))\n",
    "    )\n",
    "\n",
    "condition_2_cph = (\n",
    "    (data['internalStartZones'].str.match(r'^(1001|1002|1003|1004)$'))\n",
    "    | # or\n",
    "    pd.isna(data['internalStartZones'])\n",
    "    )\n",
    "\n",
    "data = data[(condition_1_cph)]\n",
    "data = data[(condition_2_cph)]\n",
    "\n",
    "data = data[ ~ (data['SearchStart'].str.contains(\"okation\", na=False)\n",
    "                                             | #Or\n",
    "                                             data['SearchStart'].str.contains(\"zoner\", na=False))]\n",
    "data = data[( ~ (data['SearchEnd'].str.contains(\"zoner\", na=False) \n",
    "                                            | #Or\n",
    "                                            data['SearchEnd'].str.contains(\"okation\", na=False)))]\n",
    "\n",
    "# next two filters are English filters of the first\n",
    "data = data[( ~ (data['SearchEnd'].str.contains(\"zones\", na=False) \n",
    "                                            | #Or\n",
    "                                            data['SearchEnd'].str.contains(\"ocation\", na=False)))]\n",
    "\n",
    "data = data[( ~ (data['SearchStart'].str.contains(\"zones\", na=False) \n",
    "                                            | #Or\n",
    "                                            data['SearchStart'].str.contains(\"ocation\", na=False)))]\n",
    "\n",
    "# Next filter is to remove entries where one of the matching search-x or x-stop are Null\n",
    "data = data[(\n",
    "                                        ( ~ (pd.isna(data['SearchStart'])) & ~ (pd.isna(data['SearchEnd'])))\n",
    "                                        | # Or\n",
    "                                        ( ~ (pd.isna(data['StartStop'])) & ~ (pd.isna(data['EndStop'])))\n",
    "                                        )]\n",
    "\n",
    "# Next filter removes all entries where SearchStart and SearchEnd contain the same value\n",
    "data = data[(\n",
    "                        ~(data['SearchStart'] == data['SearchEnd'])\n",
    "                        )]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting information of data\n",
    "\n",
    "We wish to create a table where we see the count of different potential relevant faults in our data such as the amount of duplicates, missing values and unique entries.\n",
    "\n",
    "It is especially the unique_value for SearchStart and SearchEnd that we are interested in, due to the field being composed of user-inputs. We wish to learn whether or not a problem will occur if two stations appear with different names in our data. And if this occurs, then how often and is it a manageable amount. \n",
    "\n",
    "From the table we see that SearchStart contain 25,404 unique values and SearchStart interestingly have 40,017 unique values. This could be due to when a user searches for a journey, usually they search for where they are going and not as much where they should start their journey. This leads to the question of whether or not the inconsistency in station-names is only relevent for SearchEnd and perphaps not as much for SearchStart. \n",
    "\n",
    "We also see that the last 3 columns of the data all appear to be empty. Therefore we will remove these columns in an attempt to save space. (Went from 476.7+ MB -> 370.8+ MB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = data.isnull().sum()\n",
    "nan_values = data.isna().sum()\n",
    "duplicates = data.duplicated().sum()\n",
    "unique_values = data.nunique()\n",
    "\n",
    "# Create a summary DataFrame\n",
    "columns = pd.DataFrame({\n",
    "    \"missing_values\": missing_values,\n",
    "    \"nan_values\": nan_values,\n",
    "    \"duplicates\": duplicates,\n",
    "    \"unique_values\": unique_values,\n",
    "})\n",
    "\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['JourneyClasses_Id', 'TravelType', 'ExtraFrom', 'ExtraTo']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['SearchStart', 'SearchEnd']].agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_counts = data[['SearchStart', 'SearchEnd']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling value_counts() on the new smaller subset of our data, we can conclude that our data consists of 323,835 unqiue combinations of a Start and End stop. From these ~300,000 the journey between CPH Airport and Copenhagen H is the most common journey. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_counts.value_counts()\n",
    "station_counts = station_counts[~(station_counts['SearchStart'].isna() & station_counts['SearchEnd'].isna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following code creates a list of pairs with the first element being start and the second element being end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = []\n",
    "\n",
    "def to_list(row):\n",
    "    seq.append([row['SearchStart'], row['SearchEnd']])\n",
    "\n",
    "station_counts.apply(to_list, axis=1)\n",
    "seq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates a dictionary out of all the entries in the list. Note that this means that we don't differentiate between start and end stations in the dict, we only care about the total number of entries for each station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_count = {}\n",
    "for (start, end) in seq:\n",
    "    #First check is not relevant anymore since the nan entries are removed.\n",
    "    if start == \"nan\" or start == 'nan':\n",
    "        print(start)\n",
    "        print(end)\n",
    "    if start in st_count:\n",
    "        st_count.update({start : st_count[start]+1})\n",
    "    else:\n",
    "        st_count[start] = 1\n",
    "    \n",
    "    if end in st_count:\n",
    "        st_count.update({end : st_count[end]+1})\n",
    "    else:\n",
    "        st_count[end] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(st_count.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code highlights different variations of stations with 'København H' in it. These are both SearchStart and SearchEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in list(st_count.keys()):\n",
    "    if type(s) is not str:\n",
    "        print(\"------\")\n",
    "        print(st_count[s])\n",
    "        print( s)\n",
    "        print(\"------\")\n",
    "    else :\n",
    "        if s.__contains__(\"København H\"):\n",
    "            print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
